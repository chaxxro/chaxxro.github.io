<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"chaxxro.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="好记性不如烂键盘">
<meta property="og:type" content="website">
<meta property="og:title" content="也无风雨也无晴">
<meta property="og:url" content="https://chaxxro.github.io/page/37/index.html">
<meta property="og:site_name" content="也无风雨也无晴">
<meta property="og:description" content="好记性不如烂键盘">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="chaxxro">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://chaxxro.github.io/page/37/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/37/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>也无风雨也无晴</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">也无风雨也无晴</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">chaxxro</p>
  <div class="site-description" itemprop="description">好记性不如烂键盘</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">408</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">存储系统</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:34:26" itemprop="dateCreated datePublished" datetime="2023-04-02T15:34:26+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Spark 存储系统负责维护所有暂存在内存与磁盘中的数据，这些数据包括 Shuffle 中间文件、RDD Cache 以及广播变量</p>
<h2 id="BlockManager"><a href="#BlockManager" class="headerlink" title="BlockManager"></a>BlockManager</h2><p>Driver 中包含 BlockManagerMaster，Executor 中包含 BlockManager</p>
<p>BlockManager 负责向 BlockManagerMaster 汇报 Executor 的内存、磁盘使用情况</p>
<p>BlockManagerMaster 与 BlockManager 之间的信息交换是双向的，但 BlockManager 之间没有信息交换，Executor 之间想交换内存、磁盘的使用情况必须通过 BlockManagerMaster</p>
<p>BlockManager 的职责，是在 Executors 中管理这 3 类数据的存储、读写与收发</p>
<h2 id="Block"><a href="#Block" class="headerlink" title="Block"></a>Block</h2><ul>
<li><p>Shuffle 中间文件消耗的是节点磁盘</p>
</li>
<li><p>广播变量主要占用节点的内存空间</p>
</li>
<li><p>RDD Cache 既可以消耗内存，也可以消耗磁盘</p>
</li>
</ul>
<p>不管是在内存、还是在磁盘，这些数据都是以数据块（Blocks）为粒度进行存取与访问的</p>
<p>BlockManager 的核心职责，在于管理数据块的元数据（Meta data），这些元数据记录并维护数据块的地址、位置、尺寸以及状态</p>
<p>只有借助元数据，BlockManager 才有可能高效地完成数据的存与取、收与发</p>
<p>BlockManager 借助 MemoryStore 管理内存中的数据存取，借助 DiskStore 管理磁盘中的数据访问</p>
<h2 id="MemoryStore"><a href="#MemoryStore" class="headerlink" title="MemoryStore"></a>MemoryStore</h2><p>MemoryStore 使用 <code>LinkedHashMap[BlockId, MemoryEntry]</code> 管理内存</p>
<img src="/2023/04/02/Spark-%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/01.png" class="">

<p>BlockId 用于标记 Block 的身份，它不是一个仅仅记录 Id 的字符串，而是一种记录 Block 元信息的数据结构，包括 Block 名字、所属 RDD、Block 对应的 RDD 数据分区、是否为广播变量、是否为 Shuffle Block 等等</p>
<p>MemoryEntry 用于承载数据实体，数据实体可以是某个 RDD 的数据分区，也可以是广播变量</p>
<h2 id="DiskStore"><a href="#DiskStore" class="headerlink" title="DiskStore"></a>DiskStore</h2><p>DiskStore 是通过维护数据块与磁盘文件的对应关系，实现磁盘数据的存取访问</p>
<p>DiskStore 使用 DiskBlockManager 来维护元数据</p>
<img src="/2023/04/02/Spark-%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/02.png" class="">

<p>DiskBlockManager 是类对象，它的 <code>getFile</code> 方法以 BlockId 为参数，返回磁盘文件</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-SparkSQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-SparkSQL/" class="post-title-link" itemprop="url">SparkSQL</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:33:21" itemprop="dateCreated datePublished" datetime="2023-04-02T15:33:21+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Spark Core 特指 Spark 底层执行引擎，包括了调度系统、存储系统、内存管理、Shuffle 管理等核心功能模块</p>
<p>Spark SQL 则凌驾于 Spark Core 之上，是一层独立的优化引擎</p>
<p>Spark Core 负责执行，而 Spark SQL 负责优化，Spark SQL 优化过后的代码，依然要交付 Spark Core 来做执行</p>
<img src="/2023/04/02/Spark-SparkSQL/01.png" class="">

<p>在 RDD 框架下开发的应用程序，会直接交付 Spark Core 运行。而使用 DataFrame API 开发的应用，则会先过一遍 Spark SQL，由 Spark SQL 优化过后再交由 Spark Core 去做执行</p>
<p>Spark SQL 包含两个核心组件：Catalyst 优化器和 Tungsten</p>
<img src="/2023/04/02/Spark-SparkSQL/02.png" class="">

<h2 id="Catalyst-优化器"><a href="#Catalyst-优化器" class="headerlink" title="Catalyst 优化器"></a>Catalyst 优化器</h2><p>Catalyst 优化器，它的职责在于创建并优化执行计划，它包含 3 个功能模块，分别是创建语法树并生成执行计划、逻辑阶段优化和物理阶段优化</p>
<h2 id="Tungsten"><a href="#Tungsten" class="headerlink" title="Tungsten"></a>Tungsten</h2><p>Tungsten 用于衔接 Catalyst 执行计划与底层的 Spark Core 执行引擎，它主要负责优化数据结果与可执行代码</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-Shuffle/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-Shuffle/" class="post-title-link" itemprop="url">Shuffle</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:32:20" itemprop="dateCreated datePublished" datetime="2023-04-02T15:32:20+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>任务调度的首要环节，是 DAGScheduler 以 Shuffle 为边界，把计算图 DAG 切割为多个执行阶段 Stages</p>
<p>在分布式计算场景中，Shuffle 为集群范围内跨节点、跨进程的数据分发</p>
<p>分布式数据集在集群内的分发，会引入大量的磁盘 I&#x2F;O 与网络 I&#x2F;O，在 DAG 的计算链条中，Shuffle 环节的执行性能是最差的</p>
<h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>以 Shuffle 为边界，计算被切割为两个执行阶段。Shuffle 之前的 Stage 叫作 Map 阶段，而把 Shuffle 之后的 Stage 称作 Reduce 阶段</p>
<p>在 Map 阶段，每个 Executors 先把自己负责的数据分区做初步聚合</p>
<p>在 Reduce 阶段，Executors 做第二次聚合（又叫全局聚合），从而完成任务</p>
<p>Shuffle 是 Map 阶段与 Reduce 阶段之间的数据交换</p>
<h2 id="中间文件"><a href="#中间文件" class="headerlink" title="中间文件"></a>中间文件</h2><p>Map 阶段与 Reduce 阶段，通过生产与消费 Shuffle 中间文件的方式，来完成集群范围内的数据交换</p>
<img src="/2023/04/02/Spark-Shuffle/01.png" class="">

<p>DAGScheduler 会为每一个 Stage 创建任务集合 TaskSet，而每一个 TaskSet 都包含多个分布式任务（Task）</p>
<p>在 Map 执行阶段，每个 Task都会生成包含 data 文件与 index 文件的 Shuffle 中间文件</p>
<p>Shuffle 文件的生成，是以 Map Task 为粒度的，Map 阶段有多少个 Map Task，就会生成多少份 Shuffle 中间文件</p>
<p>Shuffle 中间文件包含两类实体文件，一个是记录（Key，Value）键值对的 data 文件，另一个是记录键值对所属 Reduce Task 的 index 文件</p>
<p>index 文件标记了 data 文件中的哪些记录，应该由下游 Reduce 阶段中的哪些 Task（简称 Reduce Task）消费</p>
<h2 id="Shuffle-Write"><a href="#Shuffle-Write" class="headerlink" title="Shuffle Write"></a>Shuffle Write</h2><p>在生成中间文件的过程中，Spark 会借助一种类似于 Map 的数据结构，来计算、缓存并排序数据分区中的数据记录</p>
<p>这种 Map 结构的 Key 是（Reduce Task Partition ID，Record Key），而 Value 是原数据记录中的数据值</p>
<p>对于数据分区中的数据记录，Spark 会根据特定公式逐条计算记录所属的目标分区 ID，然后把主键（Reduce Task Partition ID，Record Key）和记录的数据值插入到 Map 数据结构中</p>
<p>当 Map 结构被灌满之后，Spark 根据主键对 Map 中的数据记录做排序，然后把所有内容溢出到磁盘中的临时文件</p>
<p>Map 结构被清空后，Spark 可以继续读取分区内容并继续向 Map 结构中插入数据，直到 Map 结构再次被灌满而再次溢，如此往复，直到数据分区中所有的数据记录都被处理完毕</p>
<p>最后，磁盘上存有若干个溢出的临时文件，而内存的 Map 结构中留有部分数据，Spark 使用归并排序算法对所有临时文件和 Map 结构剩余数据做合并，分别生成 data 文件、和与之对应的 index 文件</p>
<h2 id="Shuffle-Read"><a href="#Shuffle-Read" class="headerlink" title="Shuffle Read"></a>Shuffle Read</h2><p>对于每一个 Map Task 生成的中间文件，其中的目标分区数量是由 Reduce 阶段的任务数量（又叫并行度）决定的</p>
<p>对于所有 Map Task 生成的中间文件，Reduce Task 需要通过网络从不同节点的硬盘中下载并拉取属于自己的数据内容</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/" class="post-title-link" itemprop="url">共享变量</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:31:01" itemprop="dateCreated datePublished" datetime="2023-04-02T15:31:01+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>按照创建与使用方式的不同，Spark 提供了两类共享变量，分别是广播变量和累加器</p>
<h2 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h2><p>通过调用 SparkContext 下的 broadcast API 即可完成广播变量的创建</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">List</span>(<span class="string">&quot;Apache&quot;</span>, <span class="string">&quot;Spark&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> bc = sc.broadcast(list)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取广播变量内容</span></span><br><span class="line">bc.value</span><br></pre></td></tr></table></figure>

<p>如果变量在 Driver 端创建，且不是分布式数据集，则在分布式计算的过程中，Spark 需要把变量分发给每一个分布式任务</p>
<p>如果 RDD 并行度较高、或是变量的尺寸较大，那么重复的内容分发就会引入大量的网络开销与存储开销，而这些开销会大幅削弱作业的执行性能</p>
<p>Driver 端变量的分发是以 Task 为粒度的，系统中有多少个 Task，变量就需要在网络中分发多少次</p>
<p>在同一个 Executor 内部，多个不同的 Task 多次重复地缓存了同样的内容拷贝，这对内存资源是一种巨大的浪费</p>
<p>在使用广播变量之后，变量分发的粒度变成了以 Executors 为单位，同一个 Executor 内多个不同的 Tasks 只需访问同一份数据拷贝即可</p>
<p>换句话说，变量在网络中分发与存储的次数，从 RDD 的分区数量，锐减到了集群中 Executors 的个数</p>
<p>广播变量由 Driver 端定义并初始化，各个 Executors 以只读（Read only）的方式访问广播变量携带的数据内容</p>
<h2 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h2><p>累加器的主要作用是全局计数</p>
<p>累加器也是在 Driver 端定义的，但它的更新是通过在 RDD 算子中调用 add 函数完成的，在应用执行完毕之后，在 Driver 端调用累加器的 value 函数，就能获取全局计数结果</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义Long类型的累加器</span></span><br><span class="line"><span class="keyword">val</span> ac = sc.longAccumulator(<span class="string">&quot;Empty string&quot;</span>)</span><br><span class="line"></span><br><span class="line">ac.value</span><br></pre></td></tr></table></figure>

<p>SparkContext 提供了 longAccumulator、doubleAccumulator 和 collectionAccumulator</p>
<p>collectionAccumulator 允许定义集合类型的累加器，相比数值类型，集合类型可以为业务逻辑的实现，提供更多的灵活性和更大的自由度</p>
<p>累加器也是由 Driver 定义的，但 Driver 并不会向累加器中写入任何数据内容，累加器的内容更新，完全是由各个 Executors 以只写（Write only）的方式来完成，而 Driver 仅以只读的方式对更新后的内容进行访问</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">调度系统</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:29:25" itemprop="dateCreated datePublished" datetime="2023-04-02T15:29:25+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>分布式计算的精髓，在于如何把抽象的计算图，转化为实实在在的分布式计算任务，然后以并行计算的方式交付执行</p>
<p>Spark调度系统关键步骤与核心组件：</p>
<img src="/2023/04/02/Spark-%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/01.png" class="">

<p>在 SparkContext &#x2F; SparkSession 的初始化中，TaskScheduler 和 SchedulerBackend 是最早、且同时被创建的调度系统组件</p>
<p>SchedulerBackend 在构造方法中引用 TaskScheduler，而 TaskScheduler 在初始化时会引用 SchedulerBackend</p>
<p>SchedulerBackend 组件的实例化，取决于开发者指定的 Spark MasterURL，即与资源管理器（Standalone、YARN、Mesos 等）强绑定，是资源管理器在 Spark 中的代理</p>
<p>从全局视角来看，DAGScheduler 是任务调度的发起者，DAGScheduler 以 TaskSet 为粒度，向 TaskScheduler 提交任务调度请求</p>
<p>TaskScheduler 在初始化的过程中，会创建任务调度队列，任务调度队列用于缓存 DAGScheduler 提交的 TaskSets</p>
<p>TaskScheduler 结合 SchedulerBackend 提供的 WorkerOffer，按照预先设置的调度策略依次对队列中的任务进行调度</p>
<h2 id="DAGScheduler"><a href="#DAGScheduler" class="headerlink" title="DAGScheduler"></a>DAGScheduler</h2><p>DAGScheduler 把计算图 DAG 拆分为执行阶段 Stages</p>
<p>Stages 指的是不同的运行阶段，同时还要负责把 Stages 转化为任务集合 TaskSets</p>
<p>从 DAG 到 Stages 的拆分过程，那就是以 Actions 算子为起点，从后向前回溯 DAG，以 Shuffle 操作为边界去划分 Stages</p>
<p>Spark 在实际运行的过程中，会把它再细化为两个步骤。第一个步骤，就是以 Shuffle 为边界，从后向前以递归的方式，把逻辑上的计算图 DAG，转化成一个又一个 Stages</p>
<p>Stages 创建完毕之后，就到了触发计算的第二个步骤：Spark从后向前，以递归的方式，依次提请执行所有的 Stages</p>
<p>在提交 Stage 的时候，DAGScheduler 根据 Stage 是否有依赖的夫 Stage。如果依赖的夫 Stage 还没执行，则将该 Stage 的提交动作压栈，转而去请求执行夫 Stage，当夫 Stage 执行完毕的时候，DAGScheduler 通过出栈的动作，再次提请执行本 Stage</p>
<p>对于提请执行的每一个 Stage，DAGScheduler 根据 Stage 内 RDD 的 partitions 属性创建分布式任务集合 TaskSet</p>
<p>TaskSet 包含一个又一个分布式任务 Task，RDD 有多少数据分区，TaskSet 就包含多少个 Task，Task 与 RDD 的分区，是一一对应的</p>
<img src="/2023/04/02/Spark-%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/02.png" class="">

<p>stageId、stageAttemptId 标记了 Task 与执行阶段 Stage 的所属关系；taskBinary 则封装了隶属于这个执行阶段的用户代码；partition 就是刚刚说的 RDD 数据分区；locs 属性以字符串的形式记录了该任务倾向的计算节点或是 Executor ID</p>
<p>taskBinary、partition 和 locs 这三个属性，一起描述了这样一件事情：Task 应该在哪里（locs）为谁（partition）执行什么任务（taskBinary）</p>
<h2 id="SchedulerBackend"><a href="#SchedulerBackend" class="headerlink" title="SchedulerBackend"></a>SchedulerBackend</h2><p>SchedulerBackend 的核心职责就是实时汇总并掌握集群的计算资源状况</p>
<p>对于集群中可用的计算资源，SchedulerBackend 用一个叫做 ExecutorDataMap 的数据结构，来记录每一个计算节点中 Executors 的资源状态</p>
<p>ExecutorDataMap 是一种 HashMap，它的 Key 是标记 Executor 的字符串，Value 是一种叫做 ExecutorData 的数据结构</p>
<p>ExecutorData 用于封装 Executor 的资源状态，如 RPC 地址、主机地址、可用 CPU 核数和满配 CPU 核数等等，它相当于是对 Executor 做的资源画像</p>
<img src="/2023/04/02/Spark-%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/03.png" class="">

<p>对外，SchedulerBackend 以 WorkerOffer 为粒度提供计算资源</p>
<p>WorkerOffer 封装了 Executor ID、主机地址和 CPU 核数，它用来表示一份可用于调度任务的空闲资源</p>
<p>SchedulerBackend 与集群内所有 Executors 中的 ExecutorBackend 保持周期性通信，双方通过 LaunchedExecutor、RemoveExecutor、StatusUpdate 等消息来互通有无、变更可用计算资源</p>
<h2 id="TaskScheduler"><a href="#TaskScheduler" class="headerlink" title="TaskScheduler"></a>TaskScheduler</h2><p>对于给定的 WorkerOffer，TaskScheduler 是按照任务的本地倾向性，来遴选出 TaskSet 中适合调度的 Tasks</p>
<p>Task 与 RDD 的 partitions 是一一对应的，在创建 Task 的过程中，DAGScheduler 会根据数据分区的物理地址，来为 Task 设置 locs 属性。locs 属性记录了数据分区所在的计算节点、甚至是 Executor 进程 ID</p>
<p>每个任务都是自带本地倾向性的，即每个任务都有自己的调度意愿</p>
<p>这种定向到计算节点粒度的本地性倾向，Spark 中的术语叫做 NODE_LOCAL，除了定向到节点，Task 还可以定向到进程（Executor）、机架、任意地址，它们对应的术语分别是 PROCESS_LOCAL、RACK_LOCAL 和 ANY</p>
<p>对于倾向 PROCESS_LOCAL 的 Task 来说，它要求对应的数据分区在某个进程（Executor）中存有副本；而对于倾向 RACK_LOCAL 的 Task 来说，它仅要求相应的数据分区存在于同一机架即可。ANY 则等同于无定向，也就是 Task 对于分发的目的地没有倾向性，被调度到哪里都可以</p>
<img src="/2023/04/02/Spark-%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/04.png" class="">

<p>从 PROCESS_LOCAL、NODE_LOCAL、到 RACK_LOCAL、再到 ANY，Task 的本地性倾向逐渐从严苛变得宽松。TaskScheduler 接收到 WorkerOffer 之后，也正是按照这个顺序来遍历 TaskSet 中的 Tasks，优先调度本地性倾向为 PROCESS_LOCAL 的 Task，而 NODE_LOCAL 次之，RACK_LOCAL 为再次，最后是 ANY</p>
<p>Spark 调度系统的核心思想，是数据不动代码动，在任务调度的过程中，为了完成分布式计算，Spark 倾向于让数据待在原地、保持不动，而把计算任务（代码）调度、分发到数据所在的地方，从而消除数据分发引入的性能隐患。毕竟，相比分发数据，分发代码要轻量得多</p>
<h2 id="ExecutorBackend"><a href="#ExecutorBackend" class="headerlink" title="ExecutorBackend"></a>ExecutorBackend</h2><p>ExecutorBackend 收到 Tasks 后，将 Tasks 分发给 Executors 线程池中一个又一个的 CPU 线程，每个线程负责处理一个 Task</p>
<p>每当 Task 处理完毕，这些线程便会通过 ExecutorBackend，向 Driver 端的 SchedulerBackend 发送 StatusUpdate 事件，告知 Task 执行状态</p>
<p>TaskScheduler 与 SchedulerBackend 通过接力的方式，最终把状态汇报给 DAGScheduler</p>
<p>对于同一个 TaskSet 当中的 Tasks 来说，当它们分别完成了任务调度与任务执行这两个环节时，Spark 调度系统就完成了 DAG 中某一个 Stage 的任务调度</p>
<p>一个 DAG 会包含多个 Stages，一个 Stage 的结束即宣告下一个 Stage 的开始，只有当所有的 Stages 全部调度、执行完毕，才表示一个完整的 Spark 作业宣告结束</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-Rdd/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-Rdd/" class="post-title-link" itemprop="url">Rdd</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:27:27" itemprop="dateCreated datePublished" datetime="2023-04-02T15:27:27+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>RDD 是构建 Spark 分布式内存计算引擎的基石，很多 Spark 核心概念与核心组件，如 DAG 和调度系统都衍生自 RDD</p>
<img src="/2023/04/02/Spark-Rdd/01.png" class="">

<p>RDD 是一种抽象，它所囊括的是分布式计算环境中的分布式数据集</p>
<p>RDD 代表的数据集是跨进程、跨节点的，它的活动范围是整个集群</p>
<p>RDD 中承载数据的基本单元是数据分片</p>
<p>在分布式计算环境中，一份完整的数据集，会按照某种规则切割成多份数据分片。这些数据分片被均匀地分发给集群内不同的计算节点和执行进程，从而实现分布式并行计算</p>
<p>RDD 的四个重要属性：</p>
<ul>
<li><p>partitions：数据分片</p>
</li>
<li><p>partitioner：分片切割规则</p>
</li>
<li><p>dependencies：RDD 依赖</p>
</li>
<li><p>compute：转换函数</p>
</li>
</ul>
<p>数据分片的分布，是由 RDD 的 partitioner 决定的，两者是强相关的</p>
<p>在数据形态的转换过程中，每个 RDD 都会通过 dependencies 属性来记录它所依赖的前一个、或是多个 RDD</p>
<p>RDD 使用 compute 属性，来记录从父 RDD 到当前 RDD 的转换操作</p>
<h2 id="创建-RDD"><a href="#创建-RDD" class="headerlink" title="创建 RDD"></a>创建 RDD</h2><h3 id="内部数据创建"><a href="#内部数据创建" class="headerlink" title="内部数据创建"></a>内部数据创建</h3><p>在 Spark 应用中自定义的各类数据结构，如数组、列表、映射等，都属于内部数据</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">val</span> words: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;is&quot;</span>, <span class="string">&quot;cool&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>用 <code>parallelize</code> 函数来封装内部数据即可 RDD</p>
<p>在 Spark 应用内定义体量超大的数据集，其实都是不太合适的，因为数据集完全由 Driver 端创建，且创建完成后，还要在全网范围内跨节点、跨进程地分发到其他 Executors，所以往往会带来性能问题</p>
<h3 id="外部数据创建"><a href="#外部数据创建" class="headerlink" title="外部数据创建"></a>外部数据创建</h3><p>Spark 系统之外的所有数据形式，如本地文件系统或是分布式文件系统中的数据，再比如来自其他大数据组件（Hive、Hbase、RDBMS 等）的数据，都是外部数据</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lineRDD: <span class="type">RDD</span>[<span class="type">String</span>] = spark.sparkContext.textFile(file)</span><br></pre></td></tr></table></figure>

<h2 id="RDD-算子"><a href="#RDD-算子" class="headerlink" title="RDD 算子"></a>RDD 算子</h2><p>RDD 代表的是分布式数据形态，RDD 到 RDD 之间的转换，本质上是数据形态上的转换；在 RDD 的编程模型中，一共有两种算子，Transformations 类算子和 Actions 类算子；使用 Transformations 类算子，定义并描述数据形态的转换过程，然后调用 Actions 类算子，将计算结果收集起来、或是物化到磁盘</p>
<p>调用的各类 Transformations 算子，并不立即执行计算，当且仅当开发者调用 Actions 算子时，之前调用的转换算子才会付诸执行</p>
<img src="/2023/04/02/Spark-Rdd/02.png" class="">

<h2 id="内部数据转换"><a href="#内部数据转换" class="headerlink" title="内部数据转换"></a>内部数据转换</h2><ul>
<li><p><code>map</code> 算子：给定映射函数 <code>f</code>，<code>map(f)</code> 以元素为粒度对 RDD 做数据转换；由于以元素为粒度，在某些计算场景下，这个特点会严重影响执行效率</p>
</li>
<li><p><code>mapPartitions</code> 算子：以数据分区为粒度的数据转换，使用映射函数 <code>f</code> 对 RDD 进行数据转换；凡是可以共享的操作，都可以用 <code>mapPartitions</code> 算子进行优化，如创建用于连接远端数据库的 Connections 对象等</p>
</li>
<li><p><code>mapPartitionsWithIndex</code> 算子：相比 <code>mapPartitions</code>，<code>mapPartitionsWithIndex</code> 仅仅多出了一个数据分区索引，这个数据分区索引可以为获取分区编号</p>
</li>
<li><p><code>flatMap</code>：以元素为粒度，对 RDD 进行数据转换，但接受的 <code>f</code> 是元素到集合（如数组、列表等）；在逻辑上分为以元素为单位创建集合和提取集合元素</p>
</li>
<li><p><code>filter</code> 算子：对 RDD 进行过滤</p>
</li>
</ul>
<h2 id="Shuffle-计算"><a href="#Shuffle-计算" class="headerlink" title="Shuffle 计算"></a>Shuffle 计算</h2><ul>
<li><p><code>groupByKey</code>：按照 Key 做分组，包含分组和收集两步；对于元素类型为（Key，Value）键值对的 Paired RDD，groupByKey 的功能就是对 Key 值相同的元素做分组，然后把相应的 Value 值，以集合的形式收集到一起；Shuffle 时以全量原始数据记录的方式消耗磁盘与网络</p>
</li>
<li><p><code>reduceByKey</code>：根据聚合函数 f 给出的算法，把 Key 值相同的多个元素，聚合成一个元素；对于 <code>RDD[(Key，Value)]</code>，函数 f 的形参，必须是两个数值，且数值的类型必须与 Value 的类型相同，而 f 的返回值，也必须是 Value 类型的数值；Shuffle 时会在落盘与分发之前的 Map 阶段做初步的聚合计算，称之为 Map 端聚合；局限性在于其 Map 阶段与 Reduce 阶段的计算逻辑必须保持一致，这个计算逻辑统一由聚合函数 f 定义</p>
</li>
<li><p><code>aggregateByKey</code>：需要提供一个初始值，一个 Map 端聚合函数 f1，以及一个 Reduce 端聚合函数 f2，初始值类型必须与 f2 的结果类型保持一致，f1 的形参类型，必须与 Paired RDD 的 Value 类型保持一致，f2 的形参类型，必须与 f1 的结果类型保持一致</p>
</li>
</ul>
<img src="/2023/04/02/Spark-Rdd/03.png" class="">

<ul>
<li><code>sortByKey</code>：以 Key 为准对 RDD 做排序，默认升序排序</li>
</ul>
<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>在数据准备阶段，<code>union</code> 与 <code>sample</code> 用于对不同来源的数据进行合并与拆分</p>
<ul>
<li><p><code>union</code> 用于把两个类型一致、但来源不同的 RDD 进行合并，从而构成一个统一的、更大的分布式数据集；<code>union</code> 操作能够成立的前提，就是参与合并的两个 RDD 的类型必须完全一致</p>
</li>
<li><p><code>sample(withReplacement, fraction, seed)</code> 用于对 RDD 做随机采样，从而把一个较大的数据集变为一份小数据；<code>withReplacement</code> 的类型是 <code>Boolean</code>，表示采样是否有放回；<code>fraction</code> 类型是 <code>Double</code>，值域为 0 到 1，其含义是采样比例；<code>seed</code> 参数是可选的，它的类型是 <code>Long</code></p>
</li>
</ul>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>较为均衡的数据分布，对后面数据处理阶段提升 CPU 利用率更有帮助，可以整体提升执行效率</p>
<p><code>coalesce</code> 与 <code>repartition</code> 的作用就是重新调整 RDD 数据分布</p>
<p><code>repartition</code> 算子随意调整（提升或降低）RDD 的并行度，而 <code>coalesce</code> 算子则只能用于降低 RDD 并行度</p>
<p>每个 RDD 的数据分区，都对应着一个分布式 Task，而每个 Task 都需要一个 CPU 线程去执行</p>
<p>RDD 的并行度，很大程度上决定了分布式系统中 CPU 的使用效率，进而还会影响分布式系统并行计算的执行效率</p>
<p>使用 <code>repartition</code> 调整 RDD 并行度会引入 Shuffle，而 <code>coalesce</code> 则不会</p>
<p>给定 RDD，如果用 <code>repartition</code> 来调整其并行度，不论增加还是降低，对于 RDD 中的每一条数据记录，<code>repartition</code> 对它们的影响都是无差别的数据分发</p>
<p><code>coalesce</code> 在降低并行度的计算中，它采取的思路是把同一个 Executor 内的不同数据分区进行合并，这样数据并不需要跨 Executors、跨节点进行分发，因而自然不会引入 Shuffle</p>
<h2 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h2><p><code>take</code>、<code>first</code>、<code>collect</code> 把结果直接收集到 Driver 端</p>
<p><code>saveAsTextFile</code> 将计算结果持久化到（分布式）文件系统</p>
<ul>
<li><p><code>first</code> 用于收集 RDD 数据集中的任意一条数据记录</p>
</li>
<li><p><code>take</code> 用于收集多条记录</p>
</li>
<li><p><code>collect</code> 收集全部数据到 Driver，但有两处性能隐患，一个是拉取数据过程中引入的网络开销，另一个 Driver 的 OOM</p>
</li>
<li><p><code>saveAsTextFile</code> 直接通过 Executors 将 RDD 数据分区物化到文件系统，这个过程并不涉及与 Driver 端的任何交互</p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/" class="post-title-link" itemprop="url">基础架构</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:26:31" itemprop="dateCreated datePublished" datetime="2023-04-02T15:26:31+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Spark 应用程序由一个驱动器进程和一组执行器进程组成</p>
<p>驱动进程运行 <code>main</code> 函数，是 Spark 应用程序的核心，负责：</p>
<ul>
<li><p>维护 Spark 应用程序的相关信息</p>
</li>
<li><p>回应用户的程序或输入</p>
</li>
<li><p>分析任务并分发给若干执行器进行处理</p>
</li>
</ul>
<p>执行器负责执行驱动器分配的计算工作，负责：</p>
<ul>
<li><p>执行由驱动器分配的代码</p>
</li>
<li><p>将执行器的计算状态报告给驱动器</p>
</li>
</ul>
<h2 id="SparkSession"><a href="#SparkSession" class="headerlink" title="SparkSession"></a>SparkSession</h2><p>每一个 Spark 程序都需要一个 <code>SparkSession</code> 来作为驱动器</p>
<p>通过创建 <code>SparkSession</code> 来将用户命令和数据发送给 Spark</p>
<h2 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h2><p><code>DataFrame</code> 是最常见的结构化 API，是包含行和列的数据表</p>
<p>描述这些行和列的规则成为 <code>schema</code></p>
<p><code>DataFrame</code> 是分布式的，存在于集群中</p>
<h2 id="核心抽象"><a href="#核心抽象" class="headerlink" title="核心抽象"></a>核心抽象</h2><p><code>Dataset</code>、<code>DataFrame</code>、SQL 表和 <code>RDD</code> 都是分布式数据集合</p>
<h2 id="数据分区"><a href="#数据分区" class="headerlink" title="数据分区"></a>数据分区</h2><p>为了让多个执行器并行处理数据，Spark 将数据分解成多个数据块，每个数据块是一个分区</p>
<p>分区位于集群中的一台物理机上</p>
<h2 id="转换操作"><a href="#转换操作" class="headerlink" title="转换操作"></a>转换操作</h2><p>Spark 的核心数据结构在计算过程中是保持不变的</p>
<p>但可以为指定抽象的转换，转换操作是使用 Spark 表达业务逻辑的核心，在调用动作操作之前，Spark 不会真的执行转换操作</p>
<p>有两类转换操作：</p>
<ul>
<li><p>窄依赖关系的转换操作：每个输入分区仅决定一个输出分区的转换，输入输出是一对一的映射关系</p>
</li>
<li><p>宽依赖关系的转换操作 shuffle：每个输入分区决定了多个输出分区，它会在整个集群中执行互相交互分区数据，输入输出是一对多的映射关系</p>
</li>
</ul>
<p>如果是窄依赖转换，Spark 会自动执行流水线处理，全部操作在内存中执行</p>
<p>如果是宽依赖转换，Spark 会将结果写入磁盘</p>
<h2 id="惰性评估"><a href="#惰性评估" class="headerlink" title="惰性评估"></a>惰性评估</h2><p>当用户表达了一些对数据的操作时，Spark 不会立即修改数据，而是建立一个作用到原始数据的转换计划</p>
<p>Spark 首先将这个计划编译为可以在集群中高效运行的流水线式的物理执行计划，等到最后时刻才开始执行代码</p>
<h2 id="动作操作"><a href="#动作操作" class="headerlink" title="动作操作"></a>动作操作</h2><p>转换操作建立逻辑转换的计划，动作操作执行转换计划得到计算结果</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">进程模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:24:30" itemprop="dateCreated datePublished" datetime="2023-04-02T15:24:30+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在 Spark 的应用开发中，任何一个应用程序的入口，都是带有 SparkSession 的 main 函数</p>
<p>SparkSession 提供 Spark 运行时上下文的同时（如调度系统、存储系统、内存管理、RPC 通信），也可以为开发者提供创建、转换、计算分布式数据集（如 RDD）的开发 API</p>
<p>在 Spark 分布式计算环境中，有且仅有一个 JVM 进程运行这样的 main 函数，这个特殊的 JVM 进程，在 Spark 中有个专门的术语，叫作 Driver</p>
<p>Driver 最核心的作用在于，解析用户代码、构建计算流图，然后将计算流图转化为分布式任务，并把任务分发给集群中的执行进程交付运行</p>
<p>Driver 的角色是拆解任务、派活儿，而真正干活儿是执行进程</p>
<p>在 Spark 的分布式环境中，执行进程可以有一个或是多个，它们也有专门的术语，叫作 Executor</p>
<img src="/2023/04/02/Spark-%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9E%8B/01.png" class="">

<p>分布式计算的核心是任务调度，而分布式任务的调度与执行，仰仗的是 Driver 与 Executors 之间的通力合作</p>
<h2 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h2><p>在 Spark 的 Driver 进程中，DAGScheduler、TaskScheduler 和 SchedulerBackend 这三个对象通力合作，依次完成分布式任务调度的 3 个核心步骤：</p>
<ol>
<li><p>根据用户代码构建计算流图</p>
</li>
<li><p>根据计算流图拆解出分布式任务</p>
</li>
<li><p>将分布式任务分发到 Executors 中去</p>
</li>
</ol>
<p>Driver 以 Shuffle 为边界创建、分发分布式任务</p>
<h2 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h2><p>接收到任务之后，Executors 调用内部线程池，结合事先分配好的数据分片，并发地执行任务代码</p>
<p>对于一个完整的 RDD，每个 Executors 负责处理这个 RDD 的一个数据分片子集</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-DataFrame/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-DataFrame/" class="post-title-link" itemprop="url">DataFrame</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:23:13" itemprop="dateCreated datePublished" datetime="2023-04-02T15:23:13+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>RDD 中的 <code>map</code>、<code>mapPartitions</code>、<code>filter</code>、<code>flatMap</code> 算子都是高阶函数，都需要一个辅助函数 <code>f</code> 来作为形参，通过 <code>f</code> 来完成计算</p>
<p>对于 Spark 来说，辅助函数 <code>f</code> 是透明的，Spark Core 只能把函数 <code>f</code> 以闭包的形式打发到 Executor，没办法做更多的优化</p>
<p>DataFrame 与 RDD 一样，都是用来封装分布式数据集的</p>
<p>DataFrame 是携带数据模式（Data Schema）的结构化数据，而 RDD 是不携带 Schema 的分布式数据集</p>
<p>因为有了 Schema 提供明确的类型信息，Spark 才能有针对性地设计出更紧凑的数据结构，从而大幅度提升数据存储与访问效率</p>
<p>DataFrame 算子的表达能力却很弱，它定义了一套 DSL（Domain Specific Language） 算子</p>
<p>DataFrame 的算子大多数都是标量函数，它们的形参往往是结构化二维表的数据列</p>
<h2 id="从-Driver-创建-DataFrame"><a href="#从-Driver-创建-DataFrame" class="headerlink" title="从 Driver 创建 DataFrame"></a>从 Driver 创建 DataFrame</h2><p>在 Driver 端，Spark 可以直接从数组、元组、映射等数据结构创建 DataFrame</p>
<h3 id="createDataFrame-方法"><a href="#createDataFrame-方法" class="headerlink" title="createDataFrame 方法"></a>createDataFrame 方法</h3><p><code>createDataFrame</code> 方法有两个形参，第一个参数是 <code>RDD[Row]</code>，第二个参数是 <code>Schema</code></p>
<h3 id="toDF-方法"><a href="#toDF-方法" class="headerlink" title="toDF 方法"></a>toDF 方法</h3><p>通过 <code>spark.implicits</code> 中的隐式方法，可以不需要创建 <code>Schema</code> 直接由 RDD 或 Seq 创建 DataFrame</p>
<h2 id="从文件系统创建-DataFrame"><a href="#从文件系统创建-DataFrame" class="headerlink" title="从文件系统创建 DataFrame"></a>从文件系统创建 DataFrame</h2><p>使用 read API 创建 DataFrame，开发者只需要调用 SparkSession 的 read 方法，同时通过 <code>format</code>、<code>option</code> 和 <code>load</code> 提供文件格式、加载选项和文件路径</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://chaxxro.github.io/2023/04/02/Spark-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chaxxro">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="也无风雨也无晴">
      <meta itemprop="description" content="好记性不如烂键盘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 也无风雨也无晴">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/02/Spark-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" class="post-title-link" itemprop="url">内存管理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-02 15:21:17" itemprop="dateCreated datePublished" datetime="2023-04-02T15:21:17+08:00">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-25 18:11:10" itemprop="dateModified" datetime="2024-03-25T18:11:10+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>相比其他大数据计算引擎，Spark 的优势和特点就是合理而充分地使用内存</p>
<h2 id="内存区域划分"><a href="#内存区域划分" class="headerlink" title="内存区域划分"></a>内存区域划分</h2><p>对于任意一个 Executor 来说，Spark 会把内存分为 4 个区域，分别是 Reserved Memory、User Memory、Execution Memory 和 Storage Memory</p>
<img src="/2023/04/02/Spark-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/01.png" class="">

<p>Reserved Memory 固定为 300MB，不受开发者控制，它是 Spark 预留的、用来存储各种 Spark 内部对象的内存区域</p>
<p>User Memory 用于存储开发者自定义的数据结构，例如 RDD 算子中引用的数组、列表、映射等等</p>
<p>Execution Memory 用来执行分布式任务，主要包括数据的转换、过滤、映射、排序、聚合、归并等环节的内存消耗</p>
<p>Storage Memory 用于缓存分布式数据集，比如 RDD Cache、广播变量等等</p>
<p>Spark 推出了统一内存管理模式，在这种模式下，Execution Memory 和 Storage Memory 之间可以相互转化</p>
<h2 id="内存转换"><a href="#内存转换" class="headerlink" title="内存转换"></a>内存转换</h2><p>Execution Memory 和 Storage Memory 之间的转换规则，一共可以总结为 3 条：</p>
<ul>
<li><p>如果对方的内存空间有空闲，双方可以互相转换</p>
</li>
<li><p>对于 Storage Memory 转换的 Execution Memory 部分，当分布式任务有计算需要时，Storage Memory 必须立即归还内存，涉及的缓存数据要么落盘、要么清除</p>
</li>
<li><p>对于 Execution Memory 转换的 Storage Memory 部分，即便 Storage Memory 有收回内存的需要，也必须要等到分布式任务执行完毕才能释放</p>
</li>
</ul>
<h2 id="内存配置项"><a href="#内存配置项" class="headerlink" title="内存配置项"></a>内存配置项</h2><p>Executor JVM Heap 的划分，由 3 个配置项来决定</p>
<img src="/2023/04/02/Spark-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/02.png" class="">

<p>spark.executor.memory 是绝对值，它指定了 Executor 进程的 JVM Heap 总大小</p>
<p>spark.memory.fraction 和 spark.memory.storageFraction 都是比例值，它们指定了划定不同区域的空间占比</p>
<p>spark.memory.fraction 用于标记 Spark 处理分布式数据集的内存总大小，这部分内存包括 Execution Memory 和 Storage Memory 两部分</p>
<p>spark.memory.storageFraction 则用来进一步区分 Execution Memory 和 Storage Memory 的初始大小</p>
<h2 id="RDD-Cache"><a href="#RDD-Cache" class="headerlink" title="RDD Cache"></a>RDD Cache</h2><p>在 RDD 完成定义之后，在这个 RDD 之上依次调用 <code>cache</code> 和 <code>count</code> 即可，<code>cache</code> 算子告知 Spark 对 RDD 加缓存，<code>count</code> 算子将 RDD 缓存到内存</p>
<p><code>cache</code> 函数实际上会进一步调用 <code>persist(MEMORY_ONLY)</code> 来完成计算</p>
<p><code>persist</code> 算子具有更多的存储级别，允许开发者灵活地选择 Cache 的存储介质、存储形式以及副本数量</p>
<img src="/2023/04/02/Spark-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/03.png" class="">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/36/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/36/">36</a><span class="page-number current">37</span><a class="page-number" href="/page/38/">38</a><span class="space">&hellip;</span><a class="page-number" href="/page/41/">41</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/38/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">chaxxro</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  





</body>
</html>
