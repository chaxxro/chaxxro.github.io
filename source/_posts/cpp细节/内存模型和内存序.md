---
toc:
  enable: true
  number: false
  max_depth: 3
title: 内存模型和内存序
date: 2023-05-29 21:20:41
tags: cpp
categories: cpp
---

内存序是用来约束同一个线程内的内存访问排序方式的，虽然同一个线程内的代码顺序重排不会影响本线程的执行结果，但是在多线程环境下，重排造成的数据访问顺序变化会影响其它线程的访问结果

因为代码重排会对其他线程造成影响，所以引入了内存模型来解决如何合理地限制单一线程中的代码执行顺序，使得在不使用锁的情况下，既能最大化利用 CPU 的计算能力，又能保证多线程环境下不会出现逻辑错误

## 指令重排

编译器只保证在单线程环境下，执行结果的最终一致，所以指令重排在单线程环境下完全是允许的

对于编译器来说，它只知道在当前线程中数据的读写以及数据之间的依赖关系，并不知道哪些数据是在线程间共享，而且是有可能会被修改的，这些是需要开发人员去保证的

```cpp
int A, B;

void foo() {
  A = B + 1;
  B = 0;
}

int main() {
  foo();
  return 0;
}

/*
在不使用优化的情况下编译：
1. 先把变量 B 的值赋给寄存器 eax
2. 将寄存器 eax 加 1 的结果赋值给变量 A
3. 将变量 B 置为 0

使用 O2 优化编译：
1. 先把变量 B 的值赋给寄存器 eax
2. 变量 B 置零
3. 将寄存器 eax 加 1 的结果赋值给变量 A
*/
```

## 为什么需要内存模型

因为指令乱序以及多线程环境数据竞争的不确定性，导致在开发的时候经常会使用信号量或者锁来实现同步需求，进而解决数据竞争导致的不确定性问题。但是加锁或者信号量是相对接近操作系统的底层原语，每一次加锁或者解锁都有可能导致用户态和内核态的互相切换，这就导致了数据访问开销。如果锁使用不当，还可能会造成严重的性能问题，所以就需要一种语言层面的机制，既没有锁那样的大开销，又可以满足数据访问一致性的需求

引入内存模型的原因，有以下几个原因：

- 编译器优化：在某些情况下，即使是简单的语句，也不能保证是原子操作

- CPU out-of-order：CPU 为了提升计算性能，可能会调整指令的执行顺序

- CPU Cache 不一致：在 CPU Cache 的影响下，在某个 CPU 执行了指令，不会立即被其它 CPU 所看到

## 几种关系术语

### sequenced-before

sequenced-before 用于表示单线程之间，两个操作上的先后顺序，这个顺序是非对称、可以进行传递的关系

它不仅仅表示两个操作之间的先后顺序，还表示了操作结果之间的可见性关系

- 如果 A sequenced-before B，代表 A 的求值会先完成，才进行对 B 的求值，并且 A 的结果 B 可见

- 如果 A not sequenced-before B，而 B sequenced-before A，则代表先对 B 进行求值，然后对 A 进行求值

- 如果 A not sequenced-before B，而 B not sequenced-before A，则 A 和 B 都有可能先执行，甚至可以同时执行

### happens-before

happens-before 是 sequenced-before 的扩展，因为它还包含了不同线程之间的关系

happens-before 关系表示的不同线程之间的操作先后顺序，同样的也是非对称、可传递的关系

happens-before 包含两种情况，一种是同一线程内的 happens-before，等同于 sequenced-before，另一种是不同线程的 happens-before 关系

假设有一个变量 x 初始化为 0，此时有两个线程同时运行，线程 A 进行 `++x` 操作，线程 B 打印 x 的值。因为这两个线程不具备 happens-before 关系，也就是说没有保证 `++x` 操作对于打印 x 的操作是可见的，因此打印的值有可能是 0，也有可能是 1

### synchronizes-with

synchronized-with 描述的是不同线程间的同步关系，当线程 A synchronized-with 线程 B 时，代表线程 A 对某个变量或者内存的操作，对于线程 B 是可见的。换句话说 synchronized-with 就是跨线程版本的 happens-before

## C++11 支持内存模型

C++11 原子操作的很多函数都有个 `std::memory_order` 参数，这个参数就是这里所说的内存模型，其并不是类似 POD 的内存布局，而是一种数据同步模型，准确说法应该是储存一致性模型，其作用是对同一时间的读写操作进行排序

```cpp
enum memory_order {
    memory_order_relaxed,
    memory_order_consume,
    memory_order_acquire,
    memory_order_release,
    memory_order_acq_rel,
    memory_order_seq_cst
};
```

与内存模型相关的枚举类型有以上六种，但是其实分为四类

{% asset_img 01.png %}

从读写的角度进行划分的话，可以分为三种：

- 读操作 `memory_order_acquire`、`memory_order_consume`

- 写操作 `memory_order_release`

- 读-修改-写操作 `memory_order_acq_rel`、`memory_order_seq_cst`

### Relaxed ordering

最宽松的内存模型，效率也最高

在这种模型下，`std::atomic` 的 `load()` 和 `store()` 都要带上 `memory_order_relaxed` 参数

- 针对一个变量的读写操作是原子操作

- 不同线程之间针对该变量的访问操作先后顺序不能得到保证，即有可能乱序

```cpp
// 最初 x 和 y 都是 0

// 线程 1 ：
r1 = y.load(std::memory_order_relaxed); // A
x.store(r1, std::memory_order_relaxed); // B
// 线程 2 ：
r2 = x.load(std::memory_order_relaxed); // C 
y.store(42, std::memory_order_relaxed); // D

/*
允许产生结果 r1 == 42 && r2 == 42 
因为 C 和 D 之间没有依赖关系，因此编译器允许调整 C 和 D 的执行顺序
D 在 y 上的副效应，可能可见于线程 1 中的加载 A ，同时 B 在 x 上的副效应，可能可见于线程 2 中的加载 C
*/
```

一般用于多线程计数器，`std::shared_ptr` 的引用计数就是利用这个实现的

### Release-Acquire ordering

在这种模型下，`store()` 使用 `memory_order_release`，`load()` 使用 `memory_order_acquire`

#### std::memory_order_acquire

读操作 (load) 时可以指定的内存顺序

当前线程中，在 `load()` 之后的读指令不允许重排至 `load()` 之前，表示在本线程中，所有后续的读内存操作都必须在本条原子操作完成后执行，但之后的读操作是允许乱序的

#### std::memory_order_release

写操作 (store) 时可以指定的内存顺序

当前线程中，在 `store()` 之前的写指令不允许重排至 `store()` 之后，表示在本线程中，所有之前的写内存操作完成后才能执行本条原子操作，但之前的写操作是允许乱序的

#### 搭配使用

`std::memory_order_release` 和 `std::memory_order_acquire` 搭配使用，达到线程同步的效果

```cpp
std::atomic<bool> has_release;

void release(int *data) {
    if (!data) {
        data = new int[100];                            // line 1
    }
    has_release.store(true, std::memory_order_release); // line 2

    //.... do something other.
}

void acquire() {
    // 同步操作
    while (!has_release.load(std::memory_order_acquire));
    // 取值
    int a = data[0];
}

int main() {
    thread t1(release);
    thread t2(acquire);
    return 0;
}
```

#### 副作用

```cpp
std::atomic<int> net_con{0};
std::atomic<int> has_alloc{0};
char buffer[1024];
char file_content[1024];

void release_thread(void) {
    sprintf(buffer, "%s", "something_to_read_tobuffer");

    // 这两个是与buffer完全无关的代码
    // net_con表示接收到的链接
    net_con.store(1, std::memory_order_release);
    // 标记alloc memory for connection
    has_alloc.store(1, std::memory_order_release);
}

void acquire_thread(void) {
    // 这个是与两个原子变量完全无关的操作。
    if (strstr(file_content, "auth_key =")) {
        // fetch user and password
    }

    while (!has_alloc.load(std::memory_order_acquire));
    bool v = has_alloc.load(std::memory_order_acquire);
    if (v) {
         net_con.load(std::memory_order_relaxed);
}
```

buffer 与 file_content 的使用与两个原子变量就目前的这段简短的代码而言是没有任何联系；按理说，这两部分的代码是可以放到任何位置执行的，但是由于使用了 release-acquire，那么会导致的情况就是 buffer 和 file_content 的访问都被波及


### Release-Consume order

因为 Release-Acquire order 的副作用，给性能带来一定的影响；`std::memory_order_consume` 把与真正变量无关的代码剥离出去，让它们能够任意排列，不要被 release-acquire 误伤

#### std::memory_order_consume

本操作只能用来对读操作进行优化，所有后续对本原子类型的操作，必须在本操作完成之后才可以执行

`std::memory_order_acquire` 是要求后面所有的读都不得提前，`std::memory_order_consume` 是要求后面依赖于本次读的操作不能乱序

```cpp
std::atomic<int*> global_addr{nullptr};

void func(int *data) {
    int *addr = global_addr.load(std::memory_order_consume);
    int d = *data;
    int f = *(data+1);
    if (addr) {
        int x = *addr;
}
/*
global_addr、addr、x 形成了读依赖，这几个变量是不能乱序的
*/
```

### 最强约束

`std::memory_order_seq_cst` 表示最强约束，所有这条指令前面的语句不能放到后面，所有这条语句后面的语句不能放到前面来执行